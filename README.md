# AtomRL

ä¸€ä¸ªåŸå­åŒ–çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•åº“ï¼Œä¸“æ³¨äºå°†å¤æ‚çš„RLç®—æ³•åˆ†è§£ä¸ºå¯ç‹¬ç«‹è°ƒç”¨å’Œç»„åˆçš„åŸå­å‡½æ•°ã€‚

## ğŸ¯ é¡¹ç›®ç†å¿µ

AtomRLçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†å¼ºåŒ–å­¦ä¹ ç®—æ³•æ‹†è§£ä¸ºæœ€å°çš„ã€å¯å¤ç”¨çš„åŸå­å‡½æ•°å•å…ƒã€‚æ¯ä¸ªå‡½æ•°éƒ½ï¼š
- å…·æœ‰æ˜ç¡®å®šä¹‰çš„è¾“å…¥è¾“å‡ºæ¥å£
- å¯é€šè¿‡ `--help` å‚æ•°æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
- è¿”å›å¸¦æœ‰å½¢çŠ¶ä¿¡æ¯çš„å¼ é‡
- å¯ç‹¬ç«‹æµ‹è¯•å’Œè°ƒè¯•
- æ”¯æŒçµæ´»ç»„åˆæ„å»ºå¤æ‚ç®—æ³•

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install torch transformers datasets accelerate deepspeed tensorboard
```

### è¿è¡ŒGRPOè®­ç»ƒç¤ºä¾‹
```bash
cd scripts/grpos/grpo
accelerate launch --config_file config.yaml grpo.py
```

## ğŸ“¦ å½“å‰å®ç°

### GRPO (Group Relative Policy Optimization)

åŸºäºPPOçš„æ”¹è¿›ç®—æ³•ï¼Œé’ˆå¯¹è¯­è¨€æ¨¡å‹ä¼˜åŒ–è®¾è®¡ã€‚

#### ä¸»è¦ç»„ä»¶

**æ ¸å¿ƒåŸå­å‡½æ•°ï¼š**
- `generate_samples()` - æ ·æœ¬ç”Ÿæˆ
- `get_action_log_probs()` - åŠ¨ä½œæ¦‚ç‡è®¡ç®—  
- `compute_advantages()` - ä¼˜åŠ¿å‡½æ•°è®¡ç®—
- `compute_policy_loss()` - ç­–ç•¥æŸå¤±è®¡ç®—
- `compute_kl_penalty()` - KLæ•£åº¦æƒ©ç½š

**å¥–åŠ±å‡½æ•°æ¨¡å—ï¼š**
- `correctness_reward()` - ç­”æ¡ˆæ­£ç¡®æ€§å¥–åŠ±
- `digit_reward()` - æ•°å­—æ ¼å¼å¥–åŠ±
- `hard_format_reward()` - ä¸¥æ ¼æ ¼å¼å¥–åŠ±
- `mark_reward()` - æ ‡è®°å®Œæ•´æ€§å¥–åŠ±

#### ä½¿ç”¨ç¤ºä¾‹

```python
from atomrl.grpo import GRPOTrainer, GRPOArgs
from atomrl.rewards import correctness_reward, digit_reward

# é…ç½®å‚æ•°
args = GRPOArgs()
args.lr = 1e-6
args.num_generations = 4

# å®šä¹‰å¥–åŠ±å‡½æ•°ç»„åˆ
reward_functions = [correctness_reward, digit_reward]

# åˆ›å»ºè®­ç»ƒå™¨
trainer = GRPOTrainer(
    model="your-model-path",
    tokenizer="your-tokenizer-path", 
    reward_funcs=reward_functions,
    args=args
)

# å¼€å§‹è®­ç»ƒ
trainer.train()
```

## ğŸ”§ åŸå­å‡½æ•°è®¾è®¡è§„èŒƒ

### å‡½æ•°ç­¾åæ ‡å‡†
```python
def atomic_function(
    inputs: torch.Tensor,  # è¾“å…¥å¼ é‡
    mask: Optional[torch.Tensor] = None,  # å¯é€‰æ©ç 
    **kwargs
) -> Dict[str, torch.Tensor]:  # è¿”å›å­—å…¸åŒ…å«æ‰€æœ‰è¾“å‡º
    """
    åŸå­å‡½æ•°çš„æ ‡å‡†æ¨¡æ¿
    
    Args:
        inputs: è¾“å…¥å¼ é‡ [batch_size, seq_len, hidden_dim]
        mask: æ³¨æ„åŠ›æ©ç  [batch_size, seq_len]
        
    Returns:
        {
            'output': ä¸»è¦è¾“å‡ºå¼ é‡ [batch_size, output_dim],
            'intermediate': ä¸­é—´ç»“æœ [batch_size, seq_len],
            'metadata': å…ƒæ•°æ®ä¿¡æ¯
        }
    """
    pass
```

### å¸®åŠ©ä¿¡æ¯æ ‡å‡†
æ¯ä¸ªåŸå­å‡½æ•°éƒ½æ”¯æŒï¼š
```bash
python -c "from atomrl.grpo import get_action_log_probs; help(get_action_log_probs)"
```

## ğŸ“Š æ•°æ®æµå¯è§†åŒ–

```
è¾“å…¥Prompts â†’ generate_samples() â†’ é‡‡æ ·ç»“æœ
     â†“
è®¡ç®—æ¦‚ç‡ â†’ get_action_log_probs() â†’ åŠ¨ä½œæ¦‚ç‡
     â†“  
è®¡ç®—å¥–åŠ± â†’ reward_functions() â†’ å¥–åŠ±å€¼
     â†“
è®¡ç®—ä¼˜åŠ¿ â†’ compute_advantages() â†’ ä¼˜åŠ¿å‡½æ•°
     â†“
è®¡ç®—æŸå¤± â†’ compute_policy_loss() â†’ ç­–ç•¥æŸå¤±
     â†“
åå‘ä¼ æ’­ â†’ optimizer.step() â†’ å‚æ•°æ›´æ–°
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
atomrl/
â”œâ”€â”€ LICENSE                    # MITè®¸å¯è¯
â”œâ”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ scripts/                  # ç®—æ³•å®ç°è„šæœ¬
â”‚   â””â”€â”€ grpos/               # GRPOç®—æ³•
â”‚       â””â”€â”€ grpo/
â”‚           â”œâ”€â”€ config.yaml  # è®­ç»ƒé…ç½®
â”‚           â”œâ”€â”€ grpo.py      # ä¸»è¦å®ç°
â”‚           â”œâ”€â”€ prompt.txt   # ç³»ç»Ÿæç¤º
â”‚           â””â”€â”€ reward_func.py # å¥–åŠ±å‡½æ•°
â”œâ”€â”€ datasets/                # æ•°æ®é›†ç›¸å…³
â””â”€â”€ weights/                 # æ¨¡å‹æƒé‡å­˜å‚¨
```

## ğŸ”„ æ‰©å±•è®¡åˆ’

### å³å°†æ”¯æŒçš„ç®—æ³•
- [ ] PPO (Proximal Policy Optimization)
- [x] DAPO (Decoupled Clip and Dynamic sAmpling Policy Optimization)
- [ ] DPO (Direct Preference Optimization)  
- [ ] RLHF (Reinforcement Learning from Human Feedback)
- [ ] A2C (Advantage Actor-Critic)
- [ ] TRPO (Trust Region Policy Optimization)

### åŠŸèƒ½è·¯çº¿å›¾
- [ ] å‘½ä»¤è¡Œå·¥å…·æ”¯æŒ
- [ ] å¯è§†åŒ–ç•Œé¢
- [ ] å®éªŒè®°å½•å’Œå¯¹æ¯”
- [ ] è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜
- [x] åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿ä¸ºAtomRLè´¡çŒ®ä»£ç ï¼è¯·ç¡®ä¿ï¼š

1. éµå¾ªåŸå­å‡½æ•°è®¾è®¡è§„èŒƒ
2. æ·»åŠ å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
3. åŒ…å«å•å…ƒæµ‹è¯•
4. æ›´æ–°ç›¸å…³README

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä½¿ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

æ„Ÿè°¢å¼€æºç¤¾åŒºä¸ºå¼ºåŒ–å­¦ä¹ ç®—æ³•å‘å±•åšå‡ºçš„è´¡çŒ®ã€‚

---

**è®©RLç®—æ³•åƒæ­ç§¯æœ¨ä¸€æ ·ç®€å•ï¼** ğŸ§±âœ¨